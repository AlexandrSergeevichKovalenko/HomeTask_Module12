{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RbjfE7DbhotE"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":754,"status":"ok","timestamp":1730637058917,"user":{"displayName":"Александр Коваленко","userId":"02780050496098290376"},"user_tz":-60},"id":"EheDyw37hotF","outputId":"5efa83d0-3e14-4e32-811a-158db4df5433"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"]},"metadata":{},"execution_count":18}],"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","\n","x_train = x_train / 255\n","x_test = x_test / 255\n","\n","\n","\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"code","source":["#!pip uninstall keras-tuner -y\n","!pip install keras-tuner -q\n"],"metadata":{"id":"KRBhaI8Oc4FJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras_tuner\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import Dropout\n","\n","hp = keras_tuner.HyperParameters()\n","\n","def build_model(hp):\n","  model = tf.keras.Sequential()\n","  model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n","  #number of layers\n","  for i in range(hp.Int(\"num_layers\", 2,8)):\n","    model.add(tf.keras.layers.Dense(\n","        units=hp.Int(f\"units_{i}\", min_value=16, max_value=512, step=16),\n","        activation=hp.Choice(\"activation\", [\"softplus\", \"relu\", \"tanh\", \"sigmoid\", \"elu\"])\n","    ))\n","\n","    if hp.Choice(\"use_dropout\", [True, False]):\n","      model.add(tf.keras.layers.Dropout(\n","          hp.Float(f\"dropout_rate_{i}\", min_value=0.0, max_value=0.3, step=0.1)\n","      ))\n","  model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))\n","\n","  optimizer = hp.Choice(\"optimizer\",[\"adam\",\"nadam\",\"rmsprop\",\"sgd\", \"adamax\", \"adagrad\"])\n","  learning_rate = hp.Float(\"learning_rate\", min_value= 1e-5, max_value=1e-2, sampling=\"log\")\n","\n","  if optimizer == \"adam\":\n","    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n","  if optimizer == \"nadam\":\n","    optimizer = tf.keras.optimizers.Nadam(learning_rate = learning_rate)\n","  if optimizer == \"rmsprop\":\n","    optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate)\n","  if optimizer == \"sgd\":\n","    optimizer = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n","  if optimizer == \"adamax\":\n","    optimizer = tf.keras.optimizers.Adamax(learning_rate = learning_rate)\n","  if optimizer == \"adagrad\":\n","    optimizer = tf.keras.optimizers.Adagrad(learning_rate = learning_rate)\n","\n","  # Choosing optimizer and learning rate\n","  #optimizer_name = hp.Choice(\"optimizer\", [\"adam\", \"nadam\", \"rmsprop\", \"sgd\", \"adamax\", \"adagrad\"])\n","  #learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n","\n","  # Mapping optimizer names to their respective classes\n","  #optimizer_classes = {\n","  #   \"adam\": tf.keras.optimizers.Adam,\n","  #  \"nadam\": tf.keras.optimizers.Nadam,\n","  # \"rmsprop\": tf.keras.optimizers.RMSprop,\n","  # \"sgd\": tf.keras.optimizers.SGD,\n","  # \"adamax\": tf.keras.optimizers.Adamax,\n","  # \"adagrad\": tf.keras.optimizers.Adagrad\n","  #}\n","\n","  # Creating the optimizer instance\n","  #optimizer = optimizer_classes[optimizer_name](learning_rate=learning_rate)\n","  model.compile(\n","      loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n","      optimizer = optimizer,\n","      metrics = [tf.keras.metrics.SparseCategoricalAccuracy(), \"accuracy\"]\n","  )\n","\n","  hp.Choice(\"batch_size\", [32, 64,128, 256, 512])\n","\n","\n","\n","  return model\n","\n","\n","early_stopping = EarlyStopping(\n","    monitor = \"val_accuracy\",\n","    patience = 3,\n","    restore_best_weights = True\n","\n",")"],"metadata":{"id":"2Ubtks_HViYU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuner = keras_tuner.RandomSearch(\n","    hypermodel=build_model,\n","    objective=\"val_accuracy\",\n","    max_trials=25,\n","    executions_per_trial=2,\n","    overwrite=True,\n","    directory=\"/Users/alexandr/Desktop/HomeTask_12\",\n","    project_name=\"ther_bast_parametrs\",\n",")\n","\n","tuner.search_space_summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N65r79JgabJ8","executionInfo":{"status":"ok","timestamp":1730637062054,"user_tz":-60,"elapsed":5,"user":{"displayName":"Александр Коваленко","userId":"02780050496098290376"}},"outputId":"40274fd7-d02f-4357-80ef-2912db7a2053"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Search space summary\n","Default search space size: 10\n","num_layers (Int)\n","{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 1, 'sampling': 'linear'}\n","units_0 (Int)\n","{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n","activation (Choice)\n","{'default': 'softplus', 'conditions': [], 'values': ['softplus', 'relu', 'tanh', 'sigmoid', 'elu'], 'ordered': False}\n","use_dropout (Choice)\n","{'default': 1, 'conditions': [], 'values': [1, 0], 'ordered': True}\n","dropout_rate_0 (Float)\n","{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.3, 'step': 0.1, 'sampling': 'linear'}\n","units_1 (Int)\n","{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 512, 'step': 16, 'sampling': 'linear'}\n","dropout_rate_1 (Float)\n","{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.3, 'step': 0.1, 'sampling': 'linear'}\n","optimizer (Choice)\n","{'default': 'adam', 'conditions': [], 'values': ['adam', 'nadam', 'rmsprop', 'sgd', 'adamax', 'adagrad'], 'ordered': False}\n","learning_rate (Float)\n","{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n","batch_size (Choice)\n","{'default': 32, 'conditions': [], 'values': [32, 64, 128, 256, 512], 'ordered': True}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]}]},{"cell_type":"code","source":["#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n","\n","#tuner.search(x_train, y_train, epochs=50, validation_data=(x_test, y_test), callbacks=[early_stopping, reduce_lr])\n","\n","\n","tuner.search(\n","    x=x_train,\n","    y=y_train,\n","    epochs=35,\n","    validation_data=(x_test, y_test),\n","    callbacks = [early_stopping]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDUfOQwPgW2M","executionInfo":{"status":"ok","timestamp":1730662412884,"user_tz":-60,"elapsed":1658116,"user":{"displayName":"Александр Коваленко","userId":"02780050496098290376"}},"outputId":"17b06ef9-2fc6-480d-b429-25dcfc521ec3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 25 Complete [00h 09m 00s]\n","val_accuracy: 0.8789499998092651\n","\n","Best val_accuracy So Far: 0.8942999839782715\n","Total elapsed time: 07h 02m 31s\n"]}]},{"cell_type":"code","source":["# Отримання найкращої моделі\n","#best_model = tuner.get_best_models(num_models=1)[0]\n","#best_model.summary()\n","\n","# Тренування та оцінка моделі\n","#best_model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test), callbacks=[early_stopping, reduce_lr])\n","\n","#test_loss, test_acc = best_model.evaluate(x_test, y_test)\n","#print('Test accuracy:', test_acc)\n","#print('Test loss:', test_loss)\n","\n","\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","print(\"Best parameters:\")\n","print(f\"Number of layers: {best_hps.get('num_layers')}\")\n","for i in range(best_hps.get('num_layers')):\n","  print(f\"Number of neurons in the layer {i+1}: {best_hps.get(f'units_{i}')}\")\n","print(f\"Activation function:{best_hps.get('activation')}\")\n","print(f\"Optimizer: {best_hps.get('optimizer')}\")\n","if best_hps.get(\"use_dropout\"):\n","    # Проверяем, существует ли 'dropout_rate'\n","    if 'dropout_rate' in best_hps.values:\n","        dropout_rate = best_hps.get('dropout_rate')\n","        print(f\"Dropout rate: {dropout_rate}\")\n","    else:\n","        print(\"Dropout rate was not selected.\")\n","else:\n","    print(\"Dropout is not used.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P4o6bB9uZ6h1","executionInfo":{"status":"ok","timestamp":1730663310040,"user_tz":-60,"elapsed":270,"user":{"displayName":"Александр Коваленко","userId":"02780050496098290376"}},"outputId":"26a05b3c-3ebc-4e77-a0fc-91767b39e547"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best parameters:\n","Number of layers: 5\n","Number of neurons in the layer 1: 512\n","Number of neurons in the layer 2: 480\n","Number of neurons in the layer 3: 48\n","Number of neurons in the layer 4: 496\n","Number of neurons in the layer 5: 96\n","Activation function:softplus\n","Optimizer: adam\n","Dropout rate was not selected.\n"]}]},{"cell_type":"code","source":["model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n","for i in range(best_hps.get('num_layers')):\n","  model.add(tf.keras.layers.Dense(\n","      units = best_hps.get(f'units_{i}'),\n","      activation = best_hps.get('activation')\n","      ))\n","model.add(tf.keras.layers.Dense(19, activation = \"softmax\"))\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n","\n","model.compile(\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n","    optimizer = optimizer,\n","    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(), \"accuracy\"]\n","\n",")\n","\n","batch_size = best_hps.get('batch_size')\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    epochs =50,\n","    batch_size = batch_size,\n","    validation_data = (x_test, y_test),\n","    #callbacks = [early_stopping]\n","\n",")\n","\n","print(f\"Final training accuracy: {history.history['accuracy'][-1]}\")\n","print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1QSW614hD_D","executionInfo":{"status":"ok","timestamp":1730665942912,"user_tz":-60,"elapsed":569743,"user":{"displayName":"Александр Коваленко","userId":"02780050496098290376"}},"outputId":"a812b31e-27e5-41e7-8e76-bb271c8bdaf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.5891 - loss: 1.1655 - sparse_categorical_accuracy: 0.5891 - val_accuracy: 0.8159 - val_loss: 0.4964 - val_sparse_categorical_accuracy: 0.8159\n","Epoch 2/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.8342 - loss: 0.4485 - sparse_categorical_accuracy: 0.8342 - val_accuracy: 0.8359 - val_loss: 0.4537 - val_sparse_categorical_accuracy: 0.8359\n","Epoch 3/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8549 - loss: 0.3966 - sparse_categorical_accuracy: 0.8549 - val_accuracy: 0.8459 - val_loss: 0.4282 - val_sparse_categorical_accuracy: 0.8459\n","Epoch 4/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.8660 - loss: 0.3625 - sparse_categorical_accuracy: 0.8660 - val_accuracy: 0.8537 - val_loss: 0.4054 - val_sparse_categorical_accuracy: 0.8537\n","Epoch 5/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8694 - loss: 0.3526 - sparse_categorical_accuracy: 0.8694 - val_accuracy: 0.8596 - val_loss: 0.3759 - val_sparse_categorical_accuracy: 0.8596\n","Epoch 6/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.8788 - loss: 0.3252 - sparse_categorical_accuracy: 0.8788 - val_accuracy: 0.8656 - val_loss: 0.3808 - val_sparse_categorical_accuracy: 0.8656\n","Epoch 7/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.8837 - loss: 0.3128 - sparse_categorical_accuracy: 0.8837 - val_accuracy: 0.8727 - val_loss: 0.3549 - val_sparse_categorical_accuracy: 0.8727\n","Epoch 8/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.8894 - loss: 0.2964 - sparse_categorical_accuracy: 0.8894 - val_accuracy: 0.8712 - val_loss: 0.3616 - val_sparse_categorical_accuracy: 0.8712\n","Epoch 9/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8881 - loss: 0.2958 - sparse_categorical_accuracy: 0.8881 - val_accuracy: 0.8740 - val_loss: 0.3456 - val_sparse_categorical_accuracy: 0.8740\n","Epoch 10/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.8949 - loss: 0.2773 - sparse_categorical_accuracy: 0.8949 - val_accuracy: 0.8805 - val_loss: 0.3345 - val_sparse_categorical_accuracy: 0.8805\n","Epoch 11/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9003 - loss: 0.2643 - sparse_categorical_accuracy: 0.9003 - val_accuracy: 0.8794 - val_loss: 0.3396 - val_sparse_categorical_accuracy: 0.8794\n","Epoch 12/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - accuracy: 0.9009 - loss: 0.2617 - sparse_categorical_accuracy: 0.9009 - val_accuracy: 0.8837 - val_loss: 0.3370 - val_sparse_categorical_accuracy: 0.8837\n","Epoch 13/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9034 - loss: 0.2506 - sparse_categorical_accuracy: 0.9034 - val_accuracy: 0.8809 - val_loss: 0.3389 - val_sparse_categorical_accuracy: 0.8809\n","Epoch 14/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9085 - loss: 0.2446 - sparse_categorical_accuracy: 0.9085 - val_accuracy: 0.8786 - val_loss: 0.3537 - val_sparse_categorical_accuracy: 0.8786\n","Epoch 15/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9107 - loss: 0.2349 - sparse_categorical_accuracy: 0.9107 - val_accuracy: 0.8836 - val_loss: 0.3454 - val_sparse_categorical_accuracy: 0.8836\n","Epoch 16/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.9120 - loss: 0.2305 - sparse_categorical_accuracy: 0.9120 - val_accuracy: 0.8842 - val_loss: 0.3365 - val_sparse_categorical_accuracy: 0.8842\n","Epoch 17/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9176 - loss: 0.2160 - sparse_categorical_accuracy: 0.9176 - val_accuracy: 0.8815 - val_loss: 0.3511 - val_sparse_categorical_accuracy: 0.8815\n","Epoch 18/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9178 - loss: 0.2145 - sparse_categorical_accuracy: 0.9178 - val_accuracy: 0.8905 - val_loss: 0.3258 - val_sparse_categorical_accuracy: 0.8905\n","Epoch 19/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9211 - loss: 0.2037 - sparse_categorical_accuracy: 0.9211 - val_accuracy: 0.8792 - val_loss: 0.3573 - val_sparse_categorical_accuracy: 0.8792\n","Epoch 20/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.9234 - loss: 0.2009 - sparse_categorical_accuracy: 0.9234 - val_accuracy: 0.8842 - val_loss: 0.3595 - val_sparse_categorical_accuracy: 0.8842\n","Epoch 21/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9253 - loss: 0.1959 - sparse_categorical_accuracy: 0.9253 - val_accuracy: 0.8837 - val_loss: 0.3725 - val_sparse_categorical_accuracy: 0.8837\n","Epoch 22/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9260 - loss: 0.1925 - sparse_categorical_accuracy: 0.9260 - val_accuracy: 0.8941 - val_loss: 0.3482 - val_sparse_categorical_accuracy: 0.8941\n","Epoch 23/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.9323 - loss: 0.1780 - sparse_categorical_accuracy: 0.9323 - val_accuracy: 0.8896 - val_loss: 0.3547 - val_sparse_categorical_accuracy: 0.8896\n","Epoch 24/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9336 - loss: 0.1776 - sparse_categorical_accuracy: 0.9336 - val_accuracy: 0.8919 - val_loss: 0.3485 - val_sparse_categorical_accuracy: 0.8919\n","Epoch 25/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.9363 - loss: 0.1692 - sparse_categorical_accuracy: 0.9363 - val_accuracy: 0.8918 - val_loss: 0.3644 - val_sparse_categorical_accuracy: 0.8918\n","Epoch 26/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9353 - loss: 0.1687 - sparse_categorical_accuracy: 0.9353 - val_accuracy: 0.8916 - val_loss: 0.3544 - val_sparse_categorical_accuracy: 0.8916\n","Epoch 27/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9396 - loss: 0.1595 - sparse_categorical_accuracy: 0.9396 - val_accuracy: 0.8929 - val_loss: 0.3662 - val_sparse_categorical_accuracy: 0.8929\n","Epoch 28/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9407 - loss: 0.1548 - sparse_categorical_accuracy: 0.9407 - val_accuracy: 0.8842 - val_loss: 0.4131 - val_sparse_categorical_accuracy: 0.8842\n","Epoch 29/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9422 - loss: 0.1530 - sparse_categorical_accuracy: 0.9422 - val_accuracy: 0.8808 - val_loss: 0.4273 - val_sparse_categorical_accuracy: 0.8808\n","Epoch 30/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9412 - loss: 0.1515 - sparse_categorical_accuracy: 0.9412 - val_accuracy: 0.8985 - val_loss: 0.3609 - val_sparse_categorical_accuracy: 0.8985\n","Epoch 31/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9472 - loss: 0.1375 - sparse_categorical_accuracy: 0.9472 - val_accuracy: 0.8978 - val_loss: 0.3717 - val_sparse_categorical_accuracy: 0.8978\n","Epoch 32/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 35ms/step - accuracy: 0.9497 - loss: 0.1370 - sparse_categorical_accuracy: 0.9497 - val_accuracy: 0.8920 - val_loss: 0.3911 - val_sparse_categorical_accuracy: 0.8920\n","Epoch 33/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.9480 - loss: 0.1374 - sparse_categorical_accuracy: 0.9480 - val_accuracy: 0.8886 - val_loss: 0.4026 - val_sparse_categorical_accuracy: 0.8886\n","Epoch 34/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9512 - loss: 0.1289 - sparse_categorical_accuracy: 0.9512 - val_accuracy: 0.8851 - val_loss: 0.4365 - val_sparse_categorical_accuracy: 0.8851\n","Epoch 35/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9502 - loss: 0.1321 - sparse_categorical_accuracy: 0.9502 - val_accuracy: 0.8917 - val_loss: 0.4009 - val_sparse_categorical_accuracy: 0.8917\n","Epoch 36/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9530 - loss: 0.1225 - sparse_categorical_accuracy: 0.9530 - val_accuracy: 0.8961 - val_loss: 0.3975 - val_sparse_categorical_accuracy: 0.8961\n","Epoch 37/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9558 - loss: 0.1161 - sparse_categorical_accuracy: 0.9558 - val_accuracy: 0.8932 - val_loss: 0.4333 - val_sparse_categorical_accuracy: 0.8932\n","Epoch 38/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9567 - loss: 0.1133 - sparse_categorical_accuracy: 0.9567 - val_accuracy: 0.8968 - val_loss: 0.4309 - val_sparse_categorical_accuracy: 0.8968\n","Epoch 39/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9584 - loss: 0.1068 - sparse_categorical_accuracy: 0.9584 - val_accuracy: 0.8929 - val_loss: 0.4297 - val_sparse_categorical_accuracy: 0.8929\n","Epoch 40/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9585 - loss: 0.1085 - sparse_categorical_accuracy: 0.9585 - val_accuracy: 0.8971 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.8971\n","Epoch 41/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.9634 - loss: 0.0982 - sparse_categorical_accuracy: 0.9634 - val_accuracy: 0.8985 - val_loss: 0.4184 - val_sparse_categorical_accuracy: 0.8985\n","Epoch 42/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.9616 - loss: 0.0992 - sparse_categorical_accuracy: 0.9616 - val_accuracy: 0.8943 - val_loss: 0.4624 - val_sparse_categorical_accuracy: 0.8943\n","Epoch 43/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9641 - loss: 0.0951 - sparse_categorical_accuracy: 0.9641 - val_accuracy: 0.8943 - val_loss: 0.5008 - val_sparse_categorical_accuracy: 0.8943\n","Epoch 44/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9624 - loss: 0.0982 - sparse_categorical_accuracy: 0.9624 - val_accuracy: 0.8942 - val_loss: 0.4785 - val_sparse_categorical_accuracy: 0.8942\n","Epoch 45/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.9649 - loss: 0.0940 - sparse_categorical_accuracy: 0.9649 - val_accuracy: 0.8964 - val_loss: 0.4704 - val_sparse_categorical_accuracy: 0.8964\n","Epoch 46/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.9662 - loss: 0.0889 - sparse_categorical_accuracy: 0.9662 - val_accuracy: 0.8961 - val_loss: 0.4981 - val_sparse_categorical_accuracy: 0.8961\n","Epoch 47/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 46ms/step - accuracy: 0.9685 - loss: 0.0849 - sparse_categorical_accuracy: 0.9685 - val_accuracy: 0.8990 - val_loss: 0.4766 - val_sparse_categorical_accuracy: 0.8990\n","Epoch 48/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - accuracy: 0.9685 - loss: 0.0837 - sparse_categorical_accuracy: 0.9685 - val_accuracy: 0.8953 - val_loss: 0.5326 - val_sparse_categorical_accuracy: 0.8953\n","Epoch 49/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9676 - loss: 0.0867 - sparse_categorical_accuracy: 0.9676 - val_accuracy: 0.8877 - val_loss: 0.5370 - val_sparse_categorical_accuracy: 0.8877\n","Epoch 50/50\n","\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.9699 - loss: 0.0786 - sparse_categorical_accuracy: 0.9699 - val_accuracy: 0.8939 - val_loss: 0.5152 - val_sparse_categorical_accuracy: 0.8939\n","Final training accuracy: 0.969083309173584\n","Final validation accuracy: 0.8938999772071838\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}